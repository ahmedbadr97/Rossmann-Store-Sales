{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# imports and constants"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from os.path import join as join_pth\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import seaborn as sns\n",
    "# % matplotlib inline\n",
    "sns.set_style('whitegrid')\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import numpy as np\n",
    "from src import data_loader,models,model_training,utils,data_preprocessing\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<module 'src.utils' from 'D:\\\\2022 acheivments\\\\Projects\\\\DeepLearning NanoDegree\\\\Rossmann-Store-Sales\\\\src\\\\utils.py'>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload,import_module\n",
    "\n",
    "\n",
    "reload(data_loader)\n",
    "reload(data_preprocessing)\n",
    "reload(models)\n",
    "reload(model_training)\n",
    "reload(utils)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "raw_dataset_path = \"../dataset/raw\"\n",
    "prep_dataset_path=\"../dataset/prep/lstm_model\"\n",
    "nn_model_weights_pth=\"../model_weights/lstm_model\"\n",
    "nn_model_train_data_pth=\"../train_data/lstm_model\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# roadmap\n",
    "- data preparation after analysis run bulk preprocessing functions that have all preprocessing and feature engineering done at the analysis section\n",
    "- start with the neural network without lstm layers and get the best score after hyperparameters tuning\n",
    "    - create data loader for the neural network\n",
    "    - find the best hyperparameters for the first epochs\n",
    "    - train the model on the best hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preparation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## bulk preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "stores_df = pd.read_csv(join_pth(raw_dataset_path, \"store.csv\"), low_memory=False)\n",
    "stores_sales_df = pd.read_csv(join_pth(raw_dataset_path, \"train.csv\"), low_memory=False)\n",
    "\n",
    "# Sales bulk preprocessing\n",
    "stores_sales_df_prep=data_preprocessing.store_sales_prep(stores_sales_df=stores_sales_df)\n",
    "\n",
    "# Store data bulk preprocessing\n",
    "stores_data_df_prep=data_preprocessing.store_data_prep(store_data_df=stores_df)\n",
    "# merge and do bulk preprocessing\n",
    "merge_prep=data_preprocessing.merge_store_sales(sales_data_df=stores_sales_df_prep,store_data_df=stores_data_df_prep)\n",
    "\n",
    "# drop closed stores data and open column\n",
    "merge_prep=data_preprocessing.drop_closed_days(merge_prep)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-01-01 00:00:00\n",
      "2015-07-31 00:00:00\n",
      "months 31\n",
      "test months = 9\n"
     ]
    }
   ],
   "source": [
    "# we have data from jan 2013 to jul 2015\n",
    "print(merge_prep.Date.min())\n",
    "print(merge_prep.Date.max())\n",
    "\n",
    "print(f\"months {2*12 + 7}\")\n",
    "print(f\"test months = {int(31*0.3)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## train test split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size 677123\n",
      "test data size  167269\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "boundary=datetime.datetime.strptime(\"2015-02-01\",\"%Y-%m-%d\")\n",
    "train_data=merge_prep[merge_prep.Date<boundary]\n",
    "train_data=train_data.sort_values(by='Date')\n",
    "train_data=data_preprocessing.drop_extra_cols(train_data)\n",
    "train_data=data_preprocessing.hot_encoding(train_data)\n",
    "\n",
    "test_data=merge_prep[merge_prep.Date>=boundary]\n",
    "test_data=test_data.sort_values(by='Date')\n",
    "test_data=data_preprocessing.drop_extra_cols(test_data)\n",
    "test_data=data_preprocessing.hot_encoding(test_data)\n",
    "\n",
    "print(f\"train data size {len(train_data)}\")\n",
    "print(f\"test data size  {len(test_data)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 677123 entries, 621467 to 166885\n",
      "Data columns (total 28 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   Store                   677123 non-null  float64\n",
      " 1   Sales                   677123 non-null  float64\n",
      " 2   Promo                   677123 non-null  float64\n",
      " 3   SchoolHoliday           677123 non-null  float64\n",
      " 4   month                   677123 non-null  float64\n",
      " 5   day                     677123 non-null  float64\n",
      " 6   CompetitionDistance     677123 non-null  float64\n",
      " 7   Promo2                  677123 non-null  float64\n",
      " 8   Promo2Since             677123 non-null  float64\n",
      " 9   CompetitionOpenSince    677123 non-null  float64\n",
      " 10  isPromoMonth            677123 non-null  float64\n",
      " 11  DayOfWeek_1             677123 non-null  float64\n",
      " 12  DayOfWeek_2             677123 non-null  float64\n",
      " 13  DayOfWeek_3             677123 non-null  float64\n",
      " 14  DayOfWeek_4             677123 non-null  float64\n",
      " 15  DayOfWeek_5             677123 non-null  float64\n",
      " 16  DayOfWeek_6             677123 non-null  float64\n",
      " 17  DayOfWeek_7             677123 non-null  float64\n",
      " 18  StateHoliday_christmas  677123 non-null  float64\n",
      " 19  StateHoliday_easter     677123 non-null  float64\n",
      " 20  StateHoliday_public     677123 non-null  float64\n",
      " 21  StoreType_a             677123 non-null  float64\n",
      " 22  StoreType_b             677123 non-null  float64\n",
      " 23  StoreType_c             677123 non-null  float64\n",
      " 24  StoreType_d             677123 non-null  float64\n",
      " 25  Assortment_a            677123 non-null  float64\n",
      " 26  Assortment_b            677123 non-null  float64\n",
      " 27  Assortment_c            677123 non-null  float64\n",
      "dtypes: float64(28)\n",
      "memory usage: 149.8 MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 167269 entries, 76916 to 0\n",
      "Data columns (total 27 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   Store                 167269 non-null  float64\n",
      " 1   Sales                 167269 non-null  float64\n",
      " 2   Promo                 167269 non-null  float64\n",
      " 3   SchoolHoliday         167269 non-null  float64\n",
      " 4   month                 167269 non-null  float64\n",
      " 5   day                   167269 non-null  float64\n",
      " 6   CompetitionDistance   167269 non-null  float64\n",
      " 7   Promo2                167269 non-null  float64\n",
      " 8   Promo2Since           167269 non-null  float64\n",
      " 9   CompetitionOpenSince  167269 non-null  float64\n",
      " 10  isPromoMonth          167269 non-null  float64\n",
      " 11  DayOfWeek_1           167269 non-null  float64\n",
      " 12  DayOfWeek_2           167269 non-null  float64\n",
      " 13  DayOfWeek_3           167269 non-null  float64\n",
      " 14  DayOfWeek_4           167269 non-null  float64\n",
      " 15  DayOfWeek_5           167269 non-null  float64\n",
      " 16  DayOfWeek_6           167269 non-null  float64\n",
      " 17  DayOfWeek_7           167269 non-null  float64\n",
      " 18  StateHoliday_easter   167269 non-null  float64\n",
      " 19  StateHoliday_public   167269 non-null  float64\n",
      " 20  StoreType_a           167269 non-null  float64\n",
      " 21  StoreType_b           167269 non-null  float64\n",
      " 22  StoreType_c           167269 non-null  float64\n",
      " 23  StoreType_d           167269 non-null  float64\n",
      " 24  Assortment_a          167269 non-null  float64\n",
      " 25  Assortment_b          167269 non-null  float64\n",
      " 26  Assortment_c          167269 non-null  float64\n",
      "dtypes: float64(27)\n",
      "memory usage: 35.7 MB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [86]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# no Christmas days in test data so, we will add zero column to the test data\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mtest_data\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mStateHoliday_christmas\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0\u001B[39m\n\u001B[0;32m      3\u001B[0m test_data\u001B[38;5;241m=\u001B[39mtest_data[train_data\u001B[38;5;241m.\u001B[39mcolumns]\n\u001B[0;32m      4\u001B[0m test_data\u001B[38;5;241m.\u001B[39mcolumns\n",
      "\u001B[1;31mNameError\u001B[0m: name 'test_data' is not defined"
     ]
    }
   ],
   "source": [
    "# no Christmas days in test data so, we will add zero column to the test data\n",
    "test_data['StateHoliday_christmas']=0.0\n",
    "test_data=test_data[train_data.columns]\n",
    "test_data.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## arrange train columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"./assets/lstm_nn.png\"  alt=\"./assets/lstm_nn.png\"/>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data.columns))\n",
    "print(len(test_data.columns))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "# arrange columns like the picture\n",
    "\n",
    "lstm_sales_cols=['Sales','month','day','StateHoliday_christmas','StateHoliday_easter','StateHoliday_public','SchoolHoliday','Promo','CompetitionOpenSince']+[f\"DayOfWeek_{i}\"for i in range(1,8)]\n",
    "lstm_store_cols=['CompetitionDistance']+[f\"StoreType_{i}\"for i in ['a','b','c','d']]+[f\"Assortment_{i}\"for i in ['a','b','c']]\n",
    "\n",
    "cols=['Store']+lstm_sales_cols+lstm_store_cols\n",
    "train_data=train_data[cols]\n",
    "test_data=test_data[cols]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "data": {
      "text/plain": "        Store   Sales  month  day  StateHoliday_christmas  \\\n621467  682.0  3375.0    1.0  1.0                     0.0   \n386137  423.0  9643.0    1.0  1.0                     0.0   \n700661  769.0  5035.0    1.0  1.0                     0.0   \n77677    85.0  4220.0    1.0  1.0                     0.0   \n305081  335.0  2401.0    1.0  1.0                     0.0   \n\n        StateHoliday_easter  StateHoliday_public  SchoolHoliday  Promo  \\\n621467                  0.0                  1.0            1.0    0.0   \n386137                  0.0                  1.0            1.0    0.0   \n700661                  0.0                  1.0            1.0    0.0   \n77677                   0.0                  1.0            1.0    0.0   \n305081                  0.0                  1.0            1.0    0.0   \n\n        CompetitionOpenSince  ...  DayOfWeek_6  DayOfWeek_7  \\\n621467              0.000000  ...          0.0          0.0   \n386137              2.772589  ...          0.0          0.0   \n700661              0.000000  ...          0.0          0.0   \n77677               0.000000  ...          0.0          0.0   \n305081              0.000000  ...          0.0          0.0   \n\n        CompetitionDistance  StoreType_a  StoreType_b  StoreType_c  \\\n621467                 0.15          0.0          1.0          0.0   \n386137                 1.27          0.0          1.0          0.0   \n700661                 0.84          0.0          1.0          0.0   \n77677                  1.87          0.0          1.0          0.0   \n305081                 0.09          0.0          1.0          0.0   \n\n        StoreType_d  Assortment_a  Assortment_b  Assortment_c  \n621467          0.0           1.0           0.0           0.0  \n386137          0.0           1.0           0.0           0.0  \n700661          0.0           0.0           1.0           0.0  \n77677           0.0           1.0           0.0           0.0  \n305081          0.0           1.0           0.0           0.0  \n\n[5 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Store</th>\n      <th>Sales</th>\n      <th>month</th>\n      <th>day</th>\n      <th>StateHoliday_christmas</th>\n      <th>StateHoliday_easter</th>\n      <th>StateHoliday_public</th>\n      <th>SchoolHoliday</th>\n      <th>Promo</th>\n      <th>CompetitionOpenSince</th>\n      <th>...</th>\n      <th>DayOfWeek_6</th>\n      <th>DayOfWeek_7</th>\n      <th>CompetitionDistance</th>\n      <th>StoreType_a</th>\n      <th>StoreType_b</th>\n      <th>StoreType_c</th>\n      <th>StoreType_d</th>\n      <th>Assortment_a</th>\n      <th>Assortment_b</th>\n      <th>Assortment_c</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>621467</th>\n      <td>682.0</td>\n      <td>3375.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.15</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>386137</th>\n      <td>423.0</td>\n      <td>9643.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.772589</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.27</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>700661</th>\n      <td>769.0</td>\n      <td>5035.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.84</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>77677</th>\n      <td>85.0</td>\n      <td>4220.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.87</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>305081</th>\n      <td>335.0</td>\n      <td>2401.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.09</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>"
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "data": {
      "text/plain": "        Store    Sales  month  day  StateHoliday_christmas  \\\n76916    85.0  13899.0    2.0  1.0                     0.0   \n863366  948.0   9867.0    2.0  1.0                     0.0   \n666908  733.0  18263.0    2.0  1.0                     0.0   \n237578  262.0  30525.0    2.0  1.0                     0.0   \n699900  769.0  13823.0    2.0  1.0                     0.0   \n\n        StateHoliday_easter  StateHoliday_public  SchoolHoliday  Promo  \\\n76916                   0.0                  0.0            0.0    0.0   \n863366                  0.0                  0.0            0.0    0.0   \n666908                  0.0                  0.0            0.0    0.0   \n237578                  0.0                  0.0            0.0    0.0   \n699900                  0.0                  0.0            0.0    0.0   \n\n        CompetitionOpenSince  ...  DayOfWeek_6  DayOfWeek_7  \\\n76916                    0.0  ...          0.0          1.0   \n863366                   0.0  ...          0.0          1.0   \n666908                   0.0  ...          0.0          1.0   \n237578                   0.0  ...          0.0          1.0   \n699900                   0.0  ...          0.0          1.0   \n\n        CompetitionDistance  StoreType_a  StoreType_b  StoreType_c  \\\n76916                  1.87          0.0          1.0          0.0   \n863366                 1.43          0.0          1.0          0.0   \n666908                 0.86          0.0          1.0          0.0   \n237578                 1.18          0.0          1.0          0.0   \n699900                 0.84          0.0          1.0          0.0   \n\n        StoreType_d  Assortment_a  Assortment_b  Assortment_c  \n76916           0.0           1.0           0.0           0.0  \n863366          0.0           0.0           1.0           0.0  \n666908          0.0           0.0           1.0           0.0  \n237578          0.0           1.0           0.0           0.0  \n699900          0.0           0.0           1.0           0.0  \n\n[5 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Store</th>\n      <th>Sales</th>\n      <th>month</th>\n      <th>day</th>\n      <th>StateHoliday_christmas</th>\n      <th>StateHoliday_easter</th>\n      <th>StateHoliday_public</th>\n      <th>SchoolHoliday</th>\n      <th>Promo</th>\n      <th>CompetitionOpenSince</th>\n      <th>...</th>\n      <th>DayOfWeek_6</th>\n      <th>DayOfWeek_7</th>\n      <th>CompetitionDistance</th>\n      <th>StoreType_a</th>\n      <th>StoreType_b</th>\n      <th>StoreType_c</th>\n      <th>StoreType_d</th>\n      <th>Assortment_a</th>\n      <th>Assortment_b</th>\n      <th>Assortment_c</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>76916</th>\n      <td>85.0</td>\n      <td>13899.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.87</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>863366</th>\n      <td>948.0</td>\n      <td>9867.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.43</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>666908</th>\n      <td>733.0</td>\n      <td>18263.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.86</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>237578</th>\n      <td>262.0</td>\n      <td>30525.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.18</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>699900</th>\n      <td>769.0</td>\n      <td>13823.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.84</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## save train test data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "# train_data\n",
    "#   sales data\n",
    "file_name=\"lstm_sales_train.csv\"\n",
    "lstm_sales=train_data[['Store']+lstm_sales_cols]\n",
    "lstm_sales.to_csv(join_pth(prep_dataset_path,file_name),index=False)\n",
    "\n",
    "#   store data\n",
    "file_name=\"lstm_store_train.csv\"\n",
    "lstm_stores=train_data[['Store']+lstm_store_cols].drop_duplicates()\n",
    "lstm_stores.to_csv(join_pth(prep_dataset_path,file_name),index=False)\n",
    "\n",
    "# test_data\n",
    "#   sales data\n",
    "file_name=\"lstm_sales_test.csv\"\n",
    "lstm_sales=test_data[['Store']+lstm_sales_cols]\n",
    "lstm_sales.to_csv(join_pth(prep_dataset_path,file_name),index=False)\n",
    "\n",
    "#   store data\n",
    "file_name=\"lstm_store_test.csv\"\n",
    "lstm_stores=test_data[['Store']+lstm_store_cols].drop_duplicates()\n",
    "lstm_stores.to_csv(join_pth(prep_dataset_path,file_name),index=False)\n",
    "\n",
    "lstm_sales_cols_map={col_name:idx for idx,col_name in enumerate(lstm_sales_cols)}\n",
    "lstm_store_cols_map={col_name:idx for idx,col_name in enumerate(lstm_store_cols)}\n",
    "lstm_cols_idx_map={\"sales_map\":lstm_sales_cols_map,\"stores_map\":lstm_store_cols_map}\n",
    "\n",
    "utils.save_json(lstm_cols_idx_map,join_pth(prep_dataset_path,\"lstm_model_cols_map.json\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# load data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "file_name=\"lstm_sales_train.csv\"\n",
    "lstm_sales_train=pd.read_csv(join_pth(prep_dataset_path,file_name))\n",
    "file_name=\"lstm_store_train.csv\"\n",
    "lstm_store_train=pd.read_csv(join_pth(prep_dataset_path,file_name))\n",
    "\n",
    "\n",
    "file_name=\"lstm_sales_test.csv\"\n",
    "lstm_sales_test=pd.read_csv(join_pth(prep_dataset_path,file_name))\n",
    "file_name=\"lstm_store_test.csv\"\n",
    "lstm_store_test=pd.read_csv(join_pth(prep_dataset_path,file_name))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "train_dataset=data_loader.LSTMSalesDataset(lstm_sales_train,lstm_store_train)\n",
    "test_dataset=data_loader.LSTMSalesDataset(lstm_sales_test,lstm_store_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# no of months 3 as seq length = 30 so each batch contains 30 days and, we have only about 26 months\n",
    "batch_size=3\n",
    "train_loader=DataLoader(train_dataset,batch_size=batch_size)\n",
    "test_loader=DataLoader(test_dataset,batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm in shape --> torch.Size([3, 30, 16]) nn in shape --> torch.Size([3, 8]) out-> shape torch.Size([3, 30, 1])\n"
     ]
    }
   ],
   "source": [
    "# data loader test\n",
    "iterr=iter(train_loader)\n",
    "lstm_in,nn_in,out=next(iterr)\n",
    "\n",
    "print(f\"lstm in shape --> {lstm_in.shape} nn in shape --> {nn_in.shape} out-> shape {out.shape}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\graduation_project\\efficient-facenet\\venv\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "no_future_days=30\n",
    "lstm_architecture={\"input_size\":train_dataset.no_lstm_cols,\"num_layers\":1,\"hidden_size\":256}\n",
    "nn_architecture=[train_dataset.no_store_data_cols,64,16]\n",
    "fcn_architecture=[256,no_future_days]\n",
    "lstm_model=models.SalesLstm(lstm_architecture,nn_architecture,fcn_architecture,dropout_prop=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "SalesLstm(\n  (lstm): LSTM(16, 256, batch_first=True, dropout=0.5)\n  (store_data_nn): Sequential(\n    (0): Linear(in_features=8, out_features=64, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=64, out_features=16, bias=True)\n    (4): ReLU()\n  )\n  (fcn): Sequential(\n    (0): Linear(in_features=272, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=256, out_features=30, bias=True)\n    (4): ReLU()\n  )\n)"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "\n",
    "out,lstm_hidden=lstm_model(lstm_in,nn_in)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 30])"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing before training\n",
      " testing [..........] time remaining (m) = 21.85 Avg Test_Loss=61398665.88954875"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [15]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m train_losses,valid_losses\u001B[38;5;241m=\u001B[39m\u001B[43mmodel_training\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlstm_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlstm_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mlast_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43mtrain_data_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnn_model_train_data_pth\u001B[49m\u001B[43m,\u001B[49m\u001B[43mweights_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnn_model_weights_pth\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\2022 acheivments\\Projects\\DeepLearning NanoDegree\\Rossmann-Store-Sales\\src\\model_training.py:141\u001B[0m, in \u001B[0;36mlstm_train\u001B[1;34m(model, train_loader, valid_loader, n_epochs, device, last_weights, **kwargs)\u001B[0m\n\u001B[0;32m    139\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTesting before training\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    140\u001B[0m test_tracker \u001B[38;5;241m=\u001B[39m traintracker\u001B[38;5;241m.\u001B[39mTrainTracker(model, tracker_mod\u001B[38;5;241m=\u001B[39mTrackerMod\u001B[38;5;241m.\u001B[39mTEST_ONLY, test_data_size\u001B[38;5;241m=\u001B[39mvalid_size)\n\u001B[1;32m--> 141\u001B[0m test_loss \u001B[38;5;241m=\u001B[39m \u001B[43mlstm_test\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_function\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_tracker\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTest Loss :\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mround\u001B[39m(test_loss, \u001B[38;5;241m3\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    144\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m e \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_epochs):\n",
      "File \u001B[1;32mD:\\2022 acheivments\\Projects\\DeepLearning NanoDegree\\Rossmann-Store-Sales\\src\\model_training.py:90\u001B[0m, in \u001B[0;36mlstm_test\u001B[1;34m(model, valid_loader, loss_function, train_tracker, device)\u001B[0m\n\u001B[0;32m     87\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m sales_in, store_data_in, targets \u001B[38;5;129;01min\u001B[39;00m valid_loader:\n\u001B[0;32m     88\u001B[0m     sales_in, store_data_in, targets \u001B[38;5;241m=\u001B[39m sales_in\u001B[38;5;241m.\u001B[39mto(device), store_data_in\u001B[38;5;241m.\u001B[39mto(device), targets\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m---> 90\u001B[0m     predicted_output, hidden \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43msales_in\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstore_data_in\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     92\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss_function(predicted_output, targets)\n\u001B[0;32m     93\u001B[0m     avg_test_loss \u001B[38;5;241m=\u001B[39m train_tracker\u001B[38;5;241m.\u001B[39mstep(loss\u001B[38;5;241m.\u001B[39mitem())\n",
      "File \u001B[1;32mC:\\graduation_project\\efficient-facenet\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\2022 acheivments\\Projects\\DeepLearning NanoDegree\\Rossmann-Store-Sales\\src\\models.py:75\u001B[0m, in \u001B[0;36mSalesLstm.forward\u001B[1;34m(self, lstm_in, nn_in, lstm_hidden)\u001B[0m\n\u001B[0;32m     72\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m lstm_hidden \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     73\u001B[0m     lstm_hidden \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_hidden(batch_size)\n\u001B[1;32m---> 75\u001B[0m lstm_out, lstm_hidden \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlstm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlstm_in\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlstm_hidden\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;66;03m# get the last output of the sequence\u001B[39;00m\n\u001B[0;32m     78\u001B[0m lstm_out \u001B[38;5;241m=\u001B[39m lstm_out[:, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, :]\n",
      "File \u001B[1;32mC:\\graduation_project\\efficient-facenet\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mC:\\graduation_project\\efficient-facenet\\venv\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:761\u001B[0m, in \u001B[0;36mLSTM.forward\u001B[1;34m(self, input, hx)\u001B[0m\n\u001B[0;32m    759\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_forward_args(\u001B[38;5;28minput\u001B[39m, hx, batch_sizes)\n\u001B[0;32m    760\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch_sizes \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 761\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_VF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlstm\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_weights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_layers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    762\u001B[0m \u001B[43m                      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbidirectional\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_first\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    763\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    764\u001B[0m     result \u001B[38;5;241m=\u001B[39m _VF\u001B[38;5;241m.\u001B[39mlstm(\u001B[38;5;28minput\u001B[39m, batch_sizes, hx, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flat_weights, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias,\n\u001B[0;32m    765\u001B[0m                       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbidirectional)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train_losses,valid_losses=model_training.lstm_train(lstm_model,train_loader,test_loader,1,last_weights=True,train_data_dir=nn_model_train_data_pth,weights_dir=nn_model_weights_pth)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}