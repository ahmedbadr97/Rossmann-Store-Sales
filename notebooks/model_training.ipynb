{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# imports and constants"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from os.path import join as join_pth\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from IPython.core.display_functions import display\n",
    "import seaborn as sns\n",
    "# % matplotlib inline\n",
    "sns.set_style('whitegrid')\n",
    "import torch\n",
    "from src import *\n",
    "from src import data_loader,models,model_training\n",
    "from torch.utils.data.dataloader import  DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "<module 'src.model_training' from 'D:\\\\2022 acheivments\\\\Projects\\\\DeepLearning NanoDegree\\\\Rossmann-Store-Sales\\\\src\\\\model_training.py'>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload,import_module\n",
    "\n",
    "reload(data_loader)\n",
    "reload(data_preprocessing)\n",
    "reload(models)\n",
    "reload(model_training)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "raw_dataset_path = \"../dataset/raw\"\n",
    "prep_dataset_path=\"../dataset/prep\"\n",
    "nn_model_weights_pth=\"../model_weights/nn_model\"\n",
    "nn_model_train_data_pth=\"../train_data/nn_model\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# roadmap\n",
    "- data preparation after analysis run bulk preprocessing functions that have all preprocessing and feature engineering done at the analysis section\n",
    "- start with the neural network without lstm layers and get the best score after hyperparameters tuning\n",
    "    - create data loader for the neural network\n",
    "    - find the best hyperparameters for the first epochs\n",
    "    - train the model on the best hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preparation\n",
    "- after analysing , handling outliers the data and do feature engineering on the data columns in the [rossmann-store-sales-analysis](./Rossmann-Store-Sales.ipynb) notebook column by column\n",
    "- all steps are combined in the [data_preprocessing.py](../src/data_preprocessing.py) module for bulk preprocessing\n",
    "    - store data preprocessing and feature engineering\n",
    "    - store_sales preprocessing and feature engineering\n",
    "    - merging store data and store sales and add new columns\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "stores_df = pd.read_csv(join_pth(raw_dataset_path, \"store.csv\"), low_memory=False)\n",
    "stores_sales_df = pd.read_csv(join_pth(raw_dataset_path, \"train.csv\"), low_memory=False)\n",
    "\n",
    "# Sales bulk preprocessing\n",
    "stores_sales_df_prep=data_preprocessing.store_sales_prep(stores_sales_df=stores_sales_df)\n",
    "\n",
    "# Store data bulk preprocessing\n",
    "stores_data_df_prep=data_preprocessing.store_data_prep(store_data_df=stores_df)\n",
    "\n",
    "# merge and do bulk preprocessing\n",
    "merge_prep=data_preprocessing.merge_store_sales(sales_data_df=stores_sales_df_prep,store_data_df=stores_data_df_prep)\n",
    "\n",
    "# drop closed stores data and open column\n",
    "merge_prep=data_preprocessing.drop_closed_days(merge_prep)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 844392 entries, 0 to 1017207\n",
      "Data columns (total 15 columns):\n",
      " #   Column                Non-Null Count   Dtype   \n",
      "---  ------                --------------   -----   \n",
      " 0   Store                 844392 non-null  int64   \n",
      " 1   DayOfWeek             844392 non-null  category\n",
      " 2   Sales                 844392 non-null  int64   \n",
      " 3   Promo                 844392 non-null  category\n",
      " 4   StateHoliday          910 non-null     object  \n",
      " 5   SchoolHoliday         844392 non-null  category\n",
      " 6   month                 844392 non-null  int64   \n",
      " 7   day                   844392 non-null  int64   \n",
      " 8   StoreType             844392 non-null  category\n",
      " 9   Assortment            844392 non-null  category\n",
      " 10  CompetitionDistance   844392 non-null  float64 \n",
      " 11  Promo2                844392 non-null  category\n",
      " 12  Promo2Since           844392 non-null  float64 \n",
      " 13  CompetitionOpenSince  844392 non-null  int64   \n",
      " 14  isPromoMonth          844392 non-null  bool    \n",
      "dtypes: bool(1), category(6), float64(2), int64(5), object(1)\n",
      "memory usage: 63.6+ MB\n"
     ]
    }
   ],
   "source": [
    "merge_prep.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# hot-encode the categorical data\n",
    "encoded_data=data_preprocessing.hot_encoding(merged_data=merge_prep)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 844392 entries, 0 to 1017207\n",
      "Data columns (total 28 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   Store                   844392 non-null  float64\n",
      " 1   Sales                   844392 non-null  float64\n",
      " 2   Promo                   844392 non-null  float64\n",
      " 3   SchoolHoliday           844392 non-null  float64\n",
      " 4   month                   844392 non-null  float64\n",
      " 5   day                     844392 non-null  float64\n",
      " 6   CompetitionDistance     844392 non-null  float64\n",
      " 7   Promo2                  844392 non-null  float64\n",
      " 8   Promo2Since             844392 non-null  float64\n",
      " 9   CompetitionOpenSince    844392 non-null  float64\n",
      " 10  isPromoMonth            844392 non-null  float64\n",
      " 11  DayOfWeek_1             844392 non-null  float64\n",
      " 12  DayOfWeek_2             844392 non-null  float64\n",
      " 13  DayOfWeek_3             844392 non-null  float64\n",
      " 14  DayOfWeek_4             844392 non-null  float64\n",
      " 15  DayOfWeek_5             844392 non-null  float64\n",
      " 16  DayOfWeek_6             844392 non-null  float64\n",
      " 17  DayOfWeek_7             844392 non-null  float64\n",
      " 18  StateHoliday_christmas  844392 non-null  float64\n",
      " 19  StateHoliday_easter     844392 non-null  float64\n",
      " 20  StateHoliday_public     844392 non-null  float64\n",
      " 21  StoreType_a             844392 non-null  float64\n",
      " 22  StoreType_b             844392 non-null  float64\n",
      " 23  StoreType_c             844392 non-null  float64\n",
      " 24  StoreType_d             844392 non-null  float64\n",
      " 25  Assortment_a            844392 non-null  float64\n",
      " 26  Assortment_b            844392 non-null  float64\n",
      " 27  Assortment_c            844392 non-null  float64\n",
      "dtypes: float64(28)\n",
      "memory usage: 186.8 MB\n"
     ]
    }
   ],
   "source": [
    "encoded_data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "train_data,test_data=train_test_split(encoded_data,test_size=0.2)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 675513 entries, 113922 to 78624\n",
      "Data columns (total 28 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   Store                   675513 non-null  float64\n",
      " 1   Sales                   675513 non-null  float64\n",
      " 2   Promo                   675513 non-null  float64\n",
      " 3   SchoolHoliday           675513 non-null  float64\n",
      " 4   month                   675513 non-null  float64\n",
      " 5   day                     675513 non-null  float64\n",
      " 6   CompetitionDistance     675513 non-null  float64\n",
      " 7   Promo2                  675513 non-null  float64\n",
      " 8   Promo2Since             675513 non-null  float64\n",
      " 9   CompetitionOpenSince    675513 non-null  float64\n",
      " 10  isPromoMonth            675513 non-null  float64\n",
      " 11  DayOfWeek_1             675513 non-null  float64\n",
      " 12  DayOfWeek_2             675513 non-null  float64\n",
      " 13  DayOfWeek_3             675513 non-null  float64\n",
      " 14  DayOfWeek_4             675513 non-null  float64\n",
      " 15  DayOfWeek_5             675513 non-null  float64\n",
      " 16  DayOfWeek_6             675513 non-null  float64\n",
      " 17  DayOfWeek_7             675513 non-null  float64\n",
      " 18  StateHoliday_christmas  675513 non-null  float64\n",
      " 19  StateHoliday_easter     675513 non-null  float64\n",
      " 20  StateHoliday_public     675513 non-null  float64\n",
      " 21  StoreType_a             675513 non-null  float64\n",
      " 22  StoreType_b             675513 non-null  float64\n",
      " 23  StoreType_c             675513 non-null  float64\n",
      " 24  StoreType_d             675513 non-null  float64\n",
      " 25  Assortment_a            675513 non-null  float64\n",
      " 26  Assortment_b            675513 non-null  float64\n",
      " 27  Assortment_c            675513 non-null  float64\n",
      "dtypes: float64(28)\n",
      "memory usage: 149.5 MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<p style=\"font-size:18;font-weight:bold\">Save preprocessed data</p>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "file_name=\"merged_sales_train.csv\"\n",
    "train_data.to_csv(join_pth(prep_dataset_path,file_name),index=False)\n",
    "\n",
    "file_name=\"merged_sales_test.csv\"\n",
    "test_data.to_csv(join_pth(prep_dataset_path,file_name),index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Loader\n",
    "- load preprocessed data csv\n",
    "- create neural network model data loader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 675513 entries, 0 to 675512\n",
      "Data columns (total 28 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   Store                   675513 non-null  float64\n",
      " 1   Sales                   675513 non-null  float64\n",
      " 2   Promo                   675513 non-null  float64\n",
      " 3   SchoolHoliday           675513 non-null  float64\n",
      " 4   month                   675513 non-null  float64\n",
      " 5   day                     675513 non-null  float64\n",
      " 6   CompetitionDistance     675513 non-null  float64\n",
      " 7   Promo2                  675513 non-null  float64\n",
      " 8   Promo2Since             675513 non-null  float64\n",
      " 9   CompetitionOpenSince    675513 non-null  float64\n",
      " 10  isPromoMonth            675513 non-null  float64\n",
      " 11  DayOfWeek_1             675513 non-null  float64\n",
      " 12  DayOfWeek_2             675513 non-null  float64\n",
      " 13  DayOfWeek_3             675513 non-null  float64\n",
      " 14  DayOfWeek_4             675513 non-null  float64\n",
      " 15  DayOfWeek_5             675513 non-null  float64\n",
      " 16  DayOfWeek_6             675513 non-null  float64\n",
      " 17  DayOfWeek_7             675513 non-null  float64\n",
      " 18  StateHoliday_christmas  675513 non-null  float64\n",
      " 19  StateHoliday_easter     675513 non-null  float64\n",
      " 20  StateHoliday_public     675513 non-null  float64\n",
      " 21  StoreType_a             675513 non-null  float64\n",
      " 22  StoreType_b             675513 non-null  float64\n",
      " 23  StoreType_c             675513 non-null  float64\n",
      " 24  StoreType_d             675513 non-null  float64\n",
      " 25  Assortment_a            675513 non-null  float64\n",
      " 26  Assortment_b            675513 non-null  float64\n",
      " 27  Assortment_c            675513 non-null  float64\n",
      "dtypes: float64(28)\n",
      "memory usage: 144.3 MB\n"
     ]
    }
   ],
   "source": [
    "file_name=\"merged_sales_train.csv\"\n",
    "sales_train_dataset=pd.read_csv(join_pth(prep_dataset_path,file_name))\n",
    "\n",
    "file_name=\"merged_sales_test.csv\"\n",
    "sales_test_dataset=pd.read_csv(join_pth(prep_dataset_path,file_name))\n",
    "sales_train_dataset.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "nn_sales_train_dataset=data_loader.NNSalesDataset(sales_train_dataset)\n",
    "nn_sales_test_dataset=data_loader.NNSalesDataset(sales_test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000,  0.0000, 11.0000, 28.0000,  0.7600,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
      "         0.0000,  0.0000])\n",
      "torch.Size([26])\n",
      "tensor([12142.])\n"
     ]
    }
   ],
   "source": [
    "# dataset testing\n",
    "dataset_iter=iter(nn_sales_train_dataset)\n",
    "x,y=next(dataset_iter)\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merge_prep' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [7]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m display(\u001B[43mmerge_prep\u001B[49m\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m      2\u001B[0m display(encoded_data\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m      3\u001B[0m display(x)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'merge_prep' is not defined"
     ]
    }
   ],
   "source": [
    "display(merge_prep.iloc[0])\n",
    "display(encoded_data.iloc[0])\n",
    "display(x)\n",
    "display(y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "nn_sales_train_dataloader=DataLoader(nn_sales_train_dataset,batch_size=batch_size,shuffle=True)\n",
    "nn_sales_test_dataloader=DataLoader(nn_sales_test_dataset,batch_size=batch_size,shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 26])\n",
      "torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "# Data loader testing\n",
    "dataloader_iter=iter(nn_sales_train_dataloader)\n",
    "x,y=next(dataloader_iter)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "input_size=nn_sales_train_dataloader.dataset.no_cols\n",
    "hidden_shape=[256,32]\n",
    "output_size=1\n",
    "dropout_prop=0.5\n",
    "nn_model=models.SalesNN(input_size,hidden_shape,output_size,dropout_prop)\n",
    "train_losses,valid_losses=model_training.nn_model_train(nn_model,nn_sales_train_dataloader,nn_sales_test_dataloader,25,last_weights=True,train_data_dir=nn_model_train_data_pth,weights_dir=nn_model_weights_pth)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training epoch 1 time Taken (m) = 1.99 Avg Train_Loss=10589939.94000474263223\n",
      " Test  time Taken (m) = 2.36 Avg Test_Loss=7361836.41890868s=7361172.974412439223\n",
      " epoch 1 train_loss =10589939.94000474 test_loss=7361836.41890868 total_time= 4.35\n",
      " training epoch 2 time Taken (m) = 2.23 Avg Train_Loss=10154112.8407863631741285\n",
      " Test  time Taken (m) = 2.18 Avg Test_Loss=7256644.15384615s=7256394.986163768273\n",
      " epoch 2 train_loss =10154112.84078636 test_loss=7256644.15384615 total_time= 4.41\n",
      "new minimum test loss 7256644.15384615  achieved, model weights saved \n",
      " training epoch 3 time Taken (m) = 2.12 Avg Train_Loss=9996776.320369494798258713\n",
      " Test  time Taken (m) = 2.11 Avg Test_Loss=7085382.27690413s=7085184.851118273823\n",
      " epoch 3 train_loss =9996776.32036949 test_loss=7085382.27690413 total_time= 4.23\n",
      "new minimum test loss 7085382.27690413  achieved, model weights saved \n",
      " training epoch 4 time Taken (m) = 2.04 Avg Train_Loss=9913537.11364282482287797\n",
      " Test  time Taken (m) = 2.03 Avg Test_Loss=7036480.45424403s=7035145.982846852663\n",
      " epoch 4 train_loss =9913537.11364282 test_loss=7036480.45424403 total_time= 4.07\n",
      "new minimum test loss 7036480.45424403  achieved, model weights saved \n",
      " training epoch 5 time Taken (m) = 2.0 Avg Train_Loss=9832254.758905738157124533\n",
      " Test  time Taken (m) = 2.0 Avg Test_Loss=7005712.84122774ss=7005669.79473086255\n",
      " epoch 5 train_loss =9832254.75890573 test_loss=7005712.84122774 total_time= 4.0\n",
      "new minimum test loss 7005712.84122774  achieved, model weights saved \n",
      " training epoch 6 time Taken (m) = 1.93 Avg Train_Loss=9751338.45753198727691131\n",
      " Test  time Taken (m) = 1.94 Avg Test_Loss=6939382.17402425s=6939600.271322978357\n",
      " epoch 6 train_loss =9751338.45753198 test_loss=6939382.17402425 total_time= 3.87\n",
      "new minimum test loss 6939382.17402425  achieved, model weights saved \n",
      " training epoch 7 time Taken (m) = 1.93 Avg Train_Loss=9670130.17702511389052259\n",
      " Test  time Taken (m) = 1.91 Avg Test_Loss=6935135.37589996s=6935859.187452626537\n",
      " epoch 7 train_loss =9670130.17702511 test_loss=6935135.37589996 total_time= 3.84\n",
      "new minimum test loss 6935135.37589996  achieved, model weights saved \n",
      " training epoch 8 time Taken (m) = 1.9 Avg Train_Loss=9573925.460326863893314718\n",
      " Test  time Taken (m) = 1.91 Avg Test_Loss=7199621.48664267s=7199487.245924942197\n",
      " epoch 8 train_loss =9573925.46032686 test_loss=7199621.48664267 total_time= 3.8099999999999996\n",
      " training epoch 9 time Taken (m) = 1.93 Avg Train_Loss=9524851.45170535880611923\n",
      " Test  time Taken (m) = 1.94 Avg Test_Loss=6777364.16294051s=6778595.46465125977\n",
      " epoch 9 train_loss =9524851.45170535 test_loss=6777364.16294051 total_time= 3.87\n",
      "new minimum test loss 6777364.16294051  achieved, model weights saved \n",
      " training epoch 10 time Taken (m) = 1.9 Avg Train_Loss=9461433.537707256244083769\n",
      " Test  time Taken (m) = 1.89 Avg Test_Loss=7143699.38054187s=7144924.629075067767\n",
      " epoch 10 train_loss =9461433.53770725 test_loss=7143699.38054187 total_time= 3.79\n",
      " training epoch 11 time Taken (m) = 1.88 Avg Train_Loss=9411238.55987683332589613\n",
      " Test  time Taken (m) = 1.89 Avg Test_Loss=7168773.67269799s=7169266.624620922713\n",
      " epoch 11 train_loss =9411238.55987683 test_loss=7168773.67269799 total_time= 3.7699999999999996\n",
      " training epoch 12 time Taken (m) = 1.9 Avg Train_Loss=9313506.959947891549187587\n",
      " Test  time Taken (m) = 1.87 Avg Test_Loss=6985314.91744032s=6986431.48431577655\n",
      " epoch 12 train_loss =9313506.95994789 test_loss=6985314.91744032 total_time= 3.77\n",
      " training epoch 13 time Taken (m) = 1.89 Avg Train_Loss=9212063.8463761266439715\n",
      " Test  time Taken (m) = 1.89 Avg Test_Loss=6645590.40706707s=6646543.950151631323\n",
      " epoch 13 train_loss =9212063.84637612 test_loss=6645590.40706707 total_time= 3.78\n",
      "new minimum test loss 6645590.40706707  achieved, model weights saved \n",
      " training epoch 14 time Taken (m) = 1.87 Avg Train_Loss=9164881.0052581797082911\n",
      " Test  time Taken (m) = 1.88 Avg Test_Loss=6617688.7632626ss=6613796.338987878583\n",
      " epoch 14 train_loss =9164881.00525817 test_loss=6617688.7632626 total_time= 3.75\n",
      "new minimum test loss 6617688.7632626  achieved, model weights saved \n",
      " training epoch 15 time Taken (m) = 1.88 Avg Train_Loss=9093855.6589294265397548\n",
      " Test  time Taken (m) = 1.88 Avg Test_Loss=6636029.76866237s=6636942.11125853387\n",
      " epoch 15 train_loss =9093855.65892942 test_loss=6636029.76866237 total_time= 3.76\n",
      " training epoch 16 time Taken (m) = 1.88 Avg Train_Loss=9033620.1305542475649736\n",
      " Test  time Taken (m) = 1.87 Avg Test_Loss=7047062.46580144s=7047661.94778241586\n",
      " epoch 16 train_loss =9033620.13055424 test_loss=7047062.46580144 total_time= 3.75\n",
      " training epoch 17 time Taken (m) = 1.84 Avg Train_Loss=8993234.41906679073348656\n",
      " Test  time Taken (m) = 1.86 Avg Test_Loss=6768834.16838765s=6768854.139452247973\n",
      " epoch 17 train_loss =8993234.41906679 test_loss=6768834.16838765 total_time= 3.7\n",
      " training epoch 18 time Taken (m) = 1.84 Avg Train_Loss=8876074.5680483293007935\n",
      " Test  time Taken (m) = 1.86 Avg Test_Loss=7083369.66720349s=7084402.592589084487\n",
      " epoch 18 train_loss =8876074.56804832 test_loss=7083369.66720349 total_time= 3.7\n",
      " training epoch 19 time Taken (m) = 1.92 Avg Train_Loss=8853307.701681671220478367\n",
      " Test  time Taken (m) = 1.92 Avg Test_Loss=6735084.13158393s=6735978.349981054313\n",
      " epoch 19 train_loss =8853307.70168167 test_loss=6735084.13158393 total_time= 3.84\n",
      " training epoch 20 time Taken (m) = 1.86 Avg Train_Loss=8822673.38886783860158663\n",
      " Test  time Taken (m) = 1.82 Avg Test_Loss=6785295.99583175s=6786155.65125095438\n",
      " epoch 20 train_loss =8822673.38886783 test_loss=6785295.99583175 total_time= 3.68\n",
      " training epoch 21 time Taken (m) = 1.85 Avg Train_Loss=8716964.55625296652648977\n",
      " Test  time Taken (m) = 1.86 Avg Test_Loss=6522615.75715233s=6522182.05501327454\n",
      " epoch 21 train_loss =8716964.55625296 test_loss=6522615.75715233 total_time= 3.71\n",
      "new minimum test loss 6522615.75715233  achieved, model weights saved \n",
      " training epoch 22 time Taken (m) = 1.94 Avg Train_Loss=8595624.6019185263369382\n",
      " Test  time Taken (m) = 1.96 Avg Test_Loss=6742650.74227927s=6743729.610737387397\n",
      " epoch 22 train_loss =8595624.60191852 test_loss=6742650.74227927 total_time= 3.9\n",
      " training epoch 23 time Taken (m) = 2.03 Avg Train_Loss=8529555.603600199296975467\n",
      " Test  time Taken (m) = 2.02 Avg Test_Loss=6749583.83866995s=6749679.385614176597\n",
      " epoch 23 train_loss =8529555.60360019 test_loss=6749583.83866995 total_time= 4.05\n",
      " training epoch 24 time Taken (m) = 1.98 Avg Train_Loss=8490978.1576504187228115\n",
      " Test  time Taken (m) = 1.99 Avg Test_Loss=6701562.1447518ss=6701430.441243376737\n",
      " epoch 24 train_loss =8490978.1576504 test_loss=6701562.1447518 total_time= 3.9699999999999998\n",
      " training epoch 25 time Taken (m) = 1.99 Avg Train_Loss=8363885.44917101837691497\n",
      " Test  time Taken (m) = 1.98 Avg Test_Loss=6700051.13272073s=6698192.028904473423\n",
      " epoch 25 train_loss =8363885.44917101 test_loss=6700051.13272073 total_time= 3.9699999999999998\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [34]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m train_losses,valid_losses\u001B[38;5;241m=\u001B[39mmodel_training\u001B[38;5;241m.\u001B[39mnn_model_train(nn_model,nn_sales_train_dataloader,nn_sales_test_dataloader,\u001B[38;5;241m25\u001B[39m,last_weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,train_data_dir\u001B[38;5;241m=\u001B[39mnn_model_train_data_pth,weights_dir\u001B[38;5;241m=\u001B[39mnn_model_weights_pth)\n",
      "\u001B[1;31mTypeError\u001B[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1, 2]])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(x,axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}